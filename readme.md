# Описание функций

## nalyse_datasets.py

sentenize_and_predict -  передаем готовый csv, работает только со столбцом *content*. 
В него добавляется новый столбец *sentenсes*. Предложения проходят через *text_preprocessing*. 
Удаляются регулярными выражениями:
- ссылки
- номера телефонов
- Автор: 
- Фото:
- Видео:
- символы unicode

Возвращается датасет с дополнительным столбцом, содержащим словарь:
 - 'index': номер предложения,
 - 'text': текст предложения, (изначальный)
 - 'predict': предсказание фасттекста к=3,

predict_add:
 - 'turk': P_only_turk, (сумированная) вероятность тюркских языков
 - 'other': P_only_turk (сумированная) вероятность всех остальных языков языков

К тюрским языкам относятся: *ba, kk, tt, ky, tr, az, tk, uz, ug, cv, krc*

## create_only_turk_text_list

Создание списка предложений в новый столбец *only_turk_content*, которые подходят по P_valid, не подходящие будут None в списке.

Условия P_valid (0.3) и обавление предложение в *only_turk_content*,:
- Если вероятность что это тюрский больше чем 0.3
- Если предыдущее предложение и последующее относятся к тюрскому языку, при этом само предложение не прошло валидацию

Если предложение не прошло условия оно заменяется *None*
Проверяем предложения на длинну. И удаление пустых *none_cols*, обновляет index.

Получаем датасет с дополнительным столбцом *only_turk_content*, содержащим список всех тюркских предложений.
**(Содержит None на месте пропусков)**


## drop_dup_none

Добавляем новый столбец *list_in_list_without_none*, в котором будет список списоков между None

Идем по предложениям и кладем их в список, если встречаем none закрываем список и складываем его в большой список.
На выходе имеем структуру:

[['sent_1', 'sent_2', 'sent_3'],[],['sent_4', 'sent_5]]
