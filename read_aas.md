## sentenize_and_predict(df)
sentenize_and_predict -  передаем готовый csv, работает только со столбцом *content*. 
В него добавляется новый столбец *sentenсes*. Предложения проходят через *text_preprocessing*. 
Удаляются регулярными выражениями:
- ссылки
- номера телефонов
- Автор: 
- Фото:
- Видео:
- символы unicode

Возвращается датасет с дополнительным столбцом, содержащим словарь:
 - 'index': номер предложения,
 - 'text': текст предложения, (изначальный)
 - 'predict': предсказание фасттекста к=3,

predict_add:
 - 'turk': P_only_turk, (сумированная) вероятность тюркских языков
 - 'other': P_only_turk (сумированная) вероятность всех остальных языков языков

К тюрским языкам относятся: *ba, kk, tt, ky, tr, az, tk, uz, ug, cv, krc*


## create_only_turk_text_list(df)

Создание списка предложений в новый столбец *only_turk_content*, которые подходят по P_valid, не подходящие будут None в списке.

Условия P_valid (0.3) и обавление предложение в *only_turk_content*,:
- Если вероятность что это тюрский больше чем 0.3
- Если предыдущее предложение и последующее относятся к тюрскому языку, при этом само предложение не прошло валидацию

Если предложение не прошло условия оно заменяется *None*
Проверяем предложения на длинну. И удаление пустых *none_cols*, обновляет index.

Получаем датасет с дополнительным столбцом *only_turk_content*, содержащим список всех тюркских предложений.
**(Содержит None на месте пропусков)**

## drop_dup_none(df)
Создаем столбец *list_in_list_without_none*

Создан список *list_in_list_without_none* в который складываются списки предложений до None и после None. Получившийся список имеет структуру

**[['sent_1', 'sent_2','sent_3'],[],['sent_5', ''sent_6]]**

### clear_list_in_none

*list_in_list_without_none* очищается от пустых список и приобретает вид:

**[['sent_1', 'sent_2','sent_3'],['sent_5', ''sent_6]]**

## create_triplet(df.list_in_list_without_none)

На вход получает список со списками предложений без None

Входит в списки и проверяет на соответсвие требованиям:

- проверяем на количество предложений внутри списка, если предложений больше чем 3 то работает с ним, если меньше то уходим

Если предложений внутри списка больше трех, то работаем с ним.

Создаем цикл и провеходимся по предложениям, если предложение последнее или предпоследнее, то с ним не работаем

Если предложение не последнее то проверяем его отклоения от длинны и если он подходит то в новый датафрейм добавляем триплет, предложения после взятого триплета, все предложения которые были.
Имеет вид:

**triplete ['sent_1', 'sent_2', 'sent_3'] splitted_text[i+3:] ['sent_4', 'sent_5',...] all_sent['sent_1','sent_2','sent_3','sent_4','sent_5']**

## shuffle_triplet_SOP(df)

Получает на вход датаврейм с триплетами, проходится циклом по строкам и возвращает новый триплет в столбец *SOP_triplet* который прошел через *random.shuffle()*. Т.е. возвращает рандомную послеждовательность триплетов.

- triplet ВЕРНАЯ ПОСЛЕДОВАТЕЛЬНОСТЬ ТРИПЛЕТОВ
- splitted_text ПРЕДЛОЖЕНИЯ ПОСЛЕ ВЗЯТЯХ ТРИПЛЕТОВ
- all_sent ВСЕ ПРЕДЛОЖЕНИЯ
- SOP_triplet ТРИПЛЕТЫ В РАНДОМНОМ ПОРЯДКЕ (все относятся к false)